---
title: 论文翻译之《Perceptual Losses for Real-Time Style Transferand Super-Resolution》
date: 2018-05-08 20:24:09
tags: 论文翻译
---
# 在实时风格转换和超分辨率上使用感知损失函数

## Justin Johnson, Alexandre Alahi, and Li Fei-Fei

## 摘要

本文研究图像转换问题，即将一个输入图像转化到一个输出图像，最近在这个问题上使用的典型方法是训练一个使用在输出和目标图像上逐像素计算损失函数（per-pixel loss）的卷积神经网络。有研究表明高质量的图像可以通过基于预训练网络提取的高级特征定义和优化感知损失函数（perceptual loss）来生成。我们结合这些方法的有点，并且提出使用干事损失函数来训练前向网络来做图像风格转换任务，我们展示一个由Gatys等人提出的训练于解决优化问题的前向网络来做图像风格转换器的结果，相比于这个方法，我们的方法可以得到质量大致相同的图像，但是我们的速度比这个方法大约快三个数量级。我们还在单图像超分辨率问题上进行的实验，将逐像素计算的损失函数替换为感知损失函数，我们得到了视觉上令人满意的效果。

## 关键词：

风格转换器，超分辨率，深度学习

## 简介

许多经典问题可以被构筑为图像风格转换任务，即一个系统接收一些输入图像，并且将其转换到输出图像，图像处理的例子包括去躁、超分辨率、着色，这些问题中，输入图像是一个低质量图像（噪声多、分辨率低或者灰度图），而输出是一个高质量彩色图像。机器视觉问题中的例子包括语义分隔和深度估计（depth estimation）,这里的输入时彩色图像，输出图像编码了场景中的语义或者集合信息。
一个解决图像转换任务的方法是用有监督方法训练一个前向卷积神经网络，使用逐像素计算的损失函数来测量输出和目标图像之间的距离，例如被Dong等人用于超分辨率问题[1]，被Cheng等人用于着色问题[2,3]，被Long等人用于分割问题[4]，被Eigen等人用于深度和表面正则预测（depth and surface normal prediction）[5,6]，这些方法在测试阶段非常高效，仅仅需要一个前向的通过一个训练好的网络。

然而，使用这些方法逐像素计算的损失函数不能捕获输出图像和目标图像感知上的差异。例如，考虑两个在对方基础上平移一个像素的独立图像，虽然他们在感知上相似，但是在他们之间按照逐像素计算的损失函数来度量差距的话，会显示两个图像非常不同。

最近的研究显示使用感知损失函数生成的高质量图像不是基于图像像素之间的差异，而是基于预训练的卷积神经网络提取的图像的高级特征之间的差异。图像通过最小化一个损失函数来生成。这种策略已经被Mahendran等人用于特征反演[7]，被Simonyan和Yosinski等人用于特征可视化[8][9],被Gatys等人用于上下文分析和风格转换[10][11][12]，这些方法生成了高质量的图像，但是在用于解决一个优化问题的时候很慢。

在本文中我们结合了两种方法的优点，我们训练一个用于图像转换任务的前向转换网络，但是不仅只是在低级的像素信息上使用逐像素的损失函数，我们在预训练的损失网络提取出的高级特征上使用感知损失函数。在训练过程中，感知损失函数在测试实时转换网络运行时在度量图像相似度的效果上比逐像素损失函数有更好的鲁棒性。

我们在两个任务上进行了实验：风格转换和单图像超分辨率，两者本质上是病态的。

未完待续。。。