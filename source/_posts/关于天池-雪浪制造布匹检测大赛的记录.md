---
title: 关于天池-雪浪制造布匹检测大赛的记录
date: 2018-08-03 09:55:25
tags: 深度学习
categories: 工程实践
---

## 数据

使用比赛官网提供的数据，一共2022张训练图像，1种正常类别，47种瑕疵类别，共48类，正常类共1316张图片。

第一步要做的是一个二分类操作，将正常类和其他类分开。

除了正常类之外，其他类最少的只有一张训练图片，而图像大小统一为2560\*1920 大小，这样不可能直接将整张图片输入到分类器里面进行分类。

因此使用大小为256\*256的小块来滑动检测一张图片，训练数据来源于大图中的局部采样。采样代码如下:

```python
# dataset.py
# class DataSet

def _get_sample_points_per_img(self, img_size_xy, class_rects, sample_point_num = None):
        '''
        从一张图片中获取采样点
        '''
        if class_rects is None or len(class_rects) == 0:
            # 正常类，没有位置
            if sample_point_num is None:
                sample_point_num = 50
            x_sample_list = np.random.choice(list(range(img_size_xy[0])), size = sample_point_num)
            y_sample_list = np.random.choice(list(range(img_size_xy[1])), size = sample_point_num)
            
            sample_list_xy = [(y_sample_list[i], x_sample_list[i]) for i in range(sample_point_num)]

            return sample_list_xy
        else:
            # 暂时在非正常类的图片中只采样瑕疵点
            rect_point_list = [(x, y) for rect in class_rects for y in range(rect[1], rect[3]) for x in range(rect[0], rect[2])]
            area = 0
            for rect in class_rects:
                area += (rect[3] - rect[1]) * (rect[2] - rect[0])
            rect_sample_point_num = min(500, max(int(area * 0.005), 50))
            rect_sample_idx_list = np.random.choice(list(range(len(rect_point_list))), size = rect_sample_point_num, replace = False)
            rect_sample_points = []
            for idx in rect_sample_idx_list:
                rect_sample_points.append(rect_point_list[idx])

            return rect_sample_points

            # x_sample_list = np.random.choice(range(img_size_xy[0]), size = sample_point_num)
            # y_sample_list = np.random.choice(range(img_size_xy[1]), size = sample_point_num)
            
            # sample_list_yx = [(x_sample_list[i], y_sample_list[i]) for i in range(sample_point_num)]
```

训练过程按照是否是瑕疵采样来给出训练标签，最终测试的时候，使用256大小的滑动窗口来预测整张图片，将其最大值作为镇整张图片的最大值，但是这样的实际效果不太好，但看小块图像的AUC，可以达到93%，但对于整张图片，AUC只能达到0.61左右。

## 模型结构

在比赛的过程中，由于时间问题，只尝试了两种模型，第一种是简单的VGG模型,模型结构如下：

```python
# model.py
# class CNNModel

def network(self, inputs):
        # 256 256 3
        l = Conv2D(64, (3, 3), padding = 'same', name = 'conv1_1')(inputs)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Conv2D(64, (3, 3), padding = 'same', name = 'conv1_2')(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Conv2D(64, (2, 2), strides = (2, 2), padding = 'valid', name = 'down_sample_1')(l)
        # 128 128 64

        l = Conv2D(128, (3, 3), padding = 'same', name = 'conv2_1')(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Conv2D(128, (3, 3), padding = 'same', name = 'conv2_2')(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Conv2D(128, (2, 2), strides = (2, 2), padding = 'valid', name = 'down_sample_2')(l)
        # 64 64 128

        l = Conv2D(256, (3, 3), padding = 'same', name = 'conv3_1')(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Conv2D(256, (3, 3), padding = 'same', name = 'conv3_2')(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Conv2D(256, (2, 2), strides = (2, 2), padding = 'valid', name = 'down_sample_3')(l)
        # 32 32 256

        l = Conv2D(512, (3, 3), padding = 'same', name = 'conv4_1')(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Conv2D(512, (3, 3), padding = 'same', name = 'conv4_2')(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Conv2D(512, (2, 2), strides = (2, 2), padding = 'valid', name = 'down_sample_4')(l)
        # 16 16 512

        l = Flatten()(l)

        l = Dense(200)(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Dropout(0.2)(l)

        l = Dense(100)(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)

        l = Dense(2, activation = 'sigmoid', name = 'out_class')(l)
        
        return l
```

这个模型在小块数据上达到了0.93的AUC，但是滑动预测整张图片的时候AUC只有0.61。

尝试的第二种网络模型是googleNet，模型结构如下，和原始的GoogleNet稍有不同的是，辅助分类器融合到了最终的分类器中，只保留一个输出分类器：

```python
# model.py
# class CNNModel

def inception(self, inputs, out_channel):
        out_channel = out_channel // 4
        l1 = Conv2D(out_channel, (1, 1), padding = 'same')(inputs)

        l2 = Conv2D(out_channel, (1, 1), padding = 'same')(inputs)
        l2 = Conv2D(out_channel, (3, 3), padding = 'same')(l2)

        l3 = Conv2D(out_channel, (1, 1), padding = 'same')(inputs)
        l3 = Conv2D(out_channel, (3, 3), padding = 'same')(l3)
        l3 = Conv2D(out_channel, (3, 3), padding = 'same')(l3)

        l4 = MaxPooling2D((2, 2), strides = (1, 1), padding = 'same')(inputs)
        l4 = Conv2D(out_channel, (1, 1), padding = 'same')(l4)

        l = concatenate([l1, l2, l3, l4])
        return l


    def network_v2_google_net(self, inputs):
        l1 = self.inception(inputs, 64)
        l1 = MaxPooling2D((2, 2), (2, 2))(l1)
        l1 = BatchNormalization()(l1)
        l1 = PReLU()(l1)
        l1 = Dropout(0.01)(l1)

        l2 = self.inception(l1, 128)
        l2 = MaxPooling2D((2, 2), (2, 2))(l2)
        l2 = BatchNormalization()(l2)
        l2 = PReLU()(l2)
        l2 = Dropout(0.01)(l2)

        l3 = self.inception(l2, 256)
        l3 = MaxPooling2D((2, 2), (2, 2))(l3)
        l3 = BatchNormalization()(l3)
        l3 = PReLU()(l3)
        l3 = Dropout(0.01)(l3)

        l4 = self.inception(l3, 512)
        l4 = MaxPooling2D((2, 2), (2, 2))(l4)
        l4 = BatchNormalization()(l4)
        l4 = PReLU()(l4)
        l4 = Dropout(0.01)(l4)

        l2 = Flatten()(l2)
        l2 = Dense(32)(l2)
        l2 = BatchNormalization()(l2)
        l2 = PReLU()(l2)

        l3 = Flatten()(l3)
        l3 = Dense(64)(l3)
        l3 = BatchNormalization()(l3)
        l3 = PReLU()(l3)

        l4 = Flatten()(l4)
        l4 = Dense(128)(l4)
        l4 = BatchNormalization()(l4)
        l4 = PReLU()(l4)

        l = concatenate([l2, l3, l4])

        l = Dense(256)(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Dropout(0.1)(l)

        l = Dense(128)(l)
        l = BatchNormalization()(l)
        l = PReLU()(l)
        l = Dropout(0.1)(l)

        l = Dense(2, activation = 'sigmoid', name = 'out_class')(l)

        return l
```

这个模型在小块数据上的AUC可以达到92%，但是在整张图片的预测结果上AUC只有58%，效果不怎么好，

## 总结
这次因为原始图片过大，选择使用小块来滑动预测整张图片的策略不怎么好，小块预测的AUC和最终结果的AUC相差巨大，还是应该直接将整张图片直接送入分类器好一些，但是这样训练过程中模型所占内存可能比较大，训练速度慢，或许可以考虑使用fast-rcnn网络结构来进行二分类，说不定会有更好的结果。